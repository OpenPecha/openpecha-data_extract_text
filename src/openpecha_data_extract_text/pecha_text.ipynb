{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os \n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_txt_files(folder_dir: Path, dir_name: str):\n",
    "    txt_format = [\"txt\"]  # Only looking for RTF files\n",
    "\n",
    "    txt_files = []\n",
    "    \n",
    "    # Use folder_dir instead of dir_name for Path search\n",
    "    for file_format in txt_format:\n",
    "        txt_files.extend(folder_dir.rglob(f\"*.{file_format}\"))\n",
    "\n",
    "    print(f\"Found {len(txt_files)} txt files.\")  # Debugging line\n",
    "    csv_file_path = f\"{dir_name}_renamed_txt_files.csv\"\n",
    "    return rename_txt_files(txt_files, csv_file_path)\n",
    "\n",
    "    \n",
    "def rename_txt_files(file_paths: [Path], csv_file_path: str):\n",
    "    renamed_files = []\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Old Filename', 'New Filename'])\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            # Extracting the pecha_id and the original file name without its extension\n",
    "            parts = file_path.parts\n",
    "            # Assuming the first significant folder after the root is the pecha_id\n",
    "            pecha_id = parts[3] if len(parts) > 1 else \"\"\n",
    "            original_file_name = file_path.stem\n",
    "\n",
    "            # Constructing new file name based on pecha_id and the original file name, ensuring .txt extension\n",
    "            new_file_name = f\"{pecha_id}_{original_file_name}.txt\"\n",
    "            new_file_path = Path(new_file_name)  # Moving the file up one directory\n",
    "\n",
    "            # Renaming the file\n",
    "            file_path.rename(new_file_path)\n",
    "            renamed_files.append(new_file_path)\n",
    "\n",
    "            # Writing the old and new file paths to the CSV\n",
    "            csvwriter.writerow([parts[3:], str(new_file_path)])\n",
    "\n",
    "    print(f\"Renamed {len(renamed_files)} files.\")  # Debugging line\n",
    "    return renamed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 txt files.\n",
      "Renamed 0 files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_dir = Path(\"../../pecha_data\")\n",
    "get_all_txt_files(folder_dir, \"pecha_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def move_file(file_path: Path, destination_folder: Path):\n",
    "    # Ensure the destination folder exists, create if not\n",
    "    destination_folder.mkdir(parents=True, exist_ok=True)\n",
    "    # Construct the new path for the file in the destination folder\n",
    "    new_file_path = destination_folder / file_path.name\n",
    "    # Move the file\n",
    "    shutil.move(str(file_path), str(new_file_path))\n",
    "    print(f\"Moved {file_path} to {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_txt = Path(\"../../pecha_txt\")\n",
    "for file_path in file_paths:\n",
    "    move_file(file_path, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PECHA_CORRUPTED_FILES = Path(\"../../pecha_corrupted_files.txt\")\n",
    "if not PECHA_CORRUPTED_FILES.exists():\n",
    "    PECHA_CORRUPTED_FILES.touch()\n",
    "\n",
    "def save_corrupted_pecha(file_path:str):\n",
    "    with open(PECHA_CORRUPTED_FILES, \"a\") as f:\n",
    "        f.write(f\"{file_path}\\n\")\n",
    "\n",
    "\"\"\"check point system\"\"\"\n",
    "\n",
    "PECHA_CLONED_CHECKPOINT = Path(\"../../pecha_checkpoint.txt\")\n",
    "\n",
    "def load_checkpoints():\n",
    "    if PECHA_CLONED_CHECKPOINT.exists():\n",
    "        return PECHA_CLONED_CHECKPOINT.read_text().splitlines()\n",
    "\n",
    "    PECHA_CLONED_CHECKPOINT.touch()\n",
    "    return []\n",
    "\n",
    "def save_checkpoint(file_checkpoint:str):\n",
    "    with open(PECHA_CLONED_CHECKPOINT, \"a\") as f:\n",
    "        f.write(f\"{file_checkpoint}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_github_repo(repo_name: str, destination_folder: Path):\n",
    "    # Retrieve GitHub token and organization name from environment variables\n",
    "    token = os.getenv('GITHUB_TOKEN')\n",
    "    org_name = os.getenv('GITHUB_ORG')\n",
    "    \n",
    "    if not token or not org_name:\n",
    "        print(\"[ERROR]: GitHub token or organization name not found in environment variables.\")\n",
    "        return\n",
    "        \n",
    "     if destination_folder.exists() and list(destination_folder.rglob(\"*\")):\n",
    "        print(\n",
    "            f\"[INFO]: Destination folder {destination_folder} already exists and is not empty.\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        # Construct the URL with authentication token\n",
    "        repo_url = f\"https://{token}@github.com/{org_name}/{repo_name}.git\"\n",
    "        \n",
    "        # Run the git clone command\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"clone\", repo_url, str(destination_folder)],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,  # Ensure output is in text format, not bytes\n",
    "        )\n",
    "        print(f\"[SUCCESS]: Repository {repo_name} cloned successfully to {destination_folder}.\")\n",
    "        save_checkpoint(str(repo_name))\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        error_message = e.stderr  # Capture the standard error output\n",
    "        print(f\"[ERROR]: Error cloning {repo_name} repository: {error_message}\")\n",
    "        save_corrupted_pecha(f\"{repo_name}-{error_message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from typing import List\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_task(args):\n",
    "    pecha_id, output_dir, checkpoints = args\n",
    "    if f\"{str(pecha_id)}\" in checkpoints:\n",
    "            return\n",
    "    clone_github_repo(pecha_id, output_dir)    \n",
    "\n",
    "def clone_all_git_repo(all_pecha_ids: List[Path], output_dir:Path):\n",
    "    checkpoints = load_checkpoints()\n",
    "    tasks = [(pecha_id, Path(f\"{output_dir}/{pecha_id}\"), checkpoints) for pecha_id in all_pecha_ids]\n",
    "\n",
    "    num_processes = 5\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        list(tqdm(pool.imap(worker_task,tasks), total = len(tasks),  desc=\"Cloning git repo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pecha_ids = [\"OD1DF94FB\",\n",
    "                \"IB6A68EB5\",\n",
    "                \"O073CD7B3\",\n",
    "                \"I32148D7C\",\n",
    "                \"OCECD22A6\",\n",
    "                \"I0E29A756\",\n",
    "                \"OAA57DE4B\"]\n",
    "output_dir = Path(\"../../pecha_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning git repo: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 56461.78it/s]\n"
     ]
    }
   ],
   "source": [
    "clone_all_git_repo(all_pecha_ids, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
